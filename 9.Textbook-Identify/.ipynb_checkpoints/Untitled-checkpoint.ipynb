{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import book\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "books = nltk.corpus.gutenberg.fileids()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for i in range(len(books)):\n",
    "    text.append(nltk.corpus.gutenberg.words(books[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', ...],\n",
       " ['[', 'Persuasion', 'by', 'Jane', 'Austen', '1818', ...],\n",
       " ['[', 'Sense', 'and', 'Sensibility', 'by', 'Jane', ...],\n",
       " ['[', 'The', 'King', 'James', 'Bible', ']', 'The', ...],\n",
       " ['[', 'Poems', 'by', 'William', 'Blake', '1789', ']', ...],\n",
       " ['[', 'Stories', 'to', 'Tell', 'to', 'Children', 'by', ...],\n",
       " ['[', 'The', 'Adventures', 'of', 'Buster', 'Bear', ...],\n",
       " ['[', 'Alice', \"'\", 's', 'Adventures', 'in', ...],\n",
       " ['[', 'The', 'Ball', 'and', 'The', 'Cross', 'by', 'G', ...],\n",
       " ['[', 'The', 'Wisdom', 'of', 'Father', 'Brown', 'by', ...],\n",
       " ['[', 'The', 'Man', 'Who', 'Was', 'Thursday', 'by', ...],\n",
       " ['[', 'The', 'Parent', \"'\", 's', 'Assistant', ',', ...],\n",
       " ['[', 'Moby', 'Dick', 'by', 'Herman', 'Melville', ...],\n",
       " ['[', 'Paradise', 'Lost', 'by', 'John', 'Milton', ...],\n",
       " ['[', 'The', 'Tragedie', 'of', 'Julius', 'Caesar', ...],\n",
       " ['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', ...],\n",
       " ['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', ...],\n",
       " ['[', 'Leaves', 'of', 'Grass', 'by', 'Walt', 'Whitman', ...]]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(text)):\n",
    "    text[i] = ' '.join(text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "915041"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def text_process(mess):\n",
    "    lst = [x for x in mess if x not in string.punctuation+ '0123456789']\n",
    "    mess = ''.join(lst)\n",
    "    return(mess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(18):\n",
    "    text[i] = text_process(text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "876753"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'i', 'am', 'parth']\n"
     ]
    }
   ],
   "source": [
    "def list_convertor(mess):\n",
    "    return(mess.split())\n",
    "print(list_convertor('hello i am parth'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(18):\n",
    "    text[i] = list_convertor(text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "text[0] = text[0][:161800]\n",
    "text[1] = text[1][:84000]\n",
    "text[2] = text[2][:120400]\n",
    "text[3] = text[3][:791800]\n",
    "text[4] = text[4][:6800]\n",
    "text[5] = text[5][:46400]\n",
    "text[6] = text[6][:16000]\n",
    "text[7] = text[7][:27000]\n",
    "text[8] = text[8][:82400]\n",
    "text[9] = text[9][:73000]\n",
    "text[10] = text[10][:58400]\n",
    "text[11] = text[11][:170400]\n",
    "text[12] = text[12][:218000]\n",
    "text[13] = text[13][:80400]\n",
    "text[14] =text[14][:20800]\n",
    "text[15] = text[15][:30000]\n",
    "text[16] = text[16][:18000]\n",
    "text[17] = text[17][:126000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161800\n",
      "84000\n",
      "120400\n",
      "791800\n",
      "6800\n",
      "46400\n",
      "16000\n",
      "27000\n",
      "82400\n",
      "73000\n",
      "58400\n",
      "170400\n",
      "218000\n",
      "80400\n",
      "20800\n",
      "30000\n",
      "18000\n",
      "126000\n"
     ]
    }
   ],
   "source": [
    "for i in range(18):\n",
    "    print(len(text[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Method\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(18):\n",
    "    text[i] =  (list(chunks(text[i],400)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>390</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>398</th>\n",
       "      <th>399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Persuasion</td>\n",
       "      <td>by</td>\n",
       "      <td>Jane</td>\n",
       "      <td>Austen</td>\n",
       "      <td>Chapter</td>\n",
       "      <td>Sir</td>\n",
       "      <td>Walter</td>\n",
       "      <td>Elliot</td>\n",
       "      <td>of</td>\n",
       "      <td>Kellynch</td>\n",
       "      <td>...</td>\n",
       "      <td>he</td>\n",
       "      <td>did</td>\n",
       "      <td>nor</td>\n",
       "      <td>could</td>\n",
       "      <td>the</td>\n",
       "      <td>valet</td>\n",
       "      <td>of</td>\n",
       "      <td>any</td>\n",
       "      <td>new</td>\n",
       "      <td>made</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lord</td>\n",
       "      <td>be</td>\n",
       "      <td>more</td>\n",
       "      <td>delighted</td>\n",
       "      <td>with</td>\n",
       "      <td>the</td>\n",
       "      <td>place</td>\n",
       "      <td>he</td>\n",
       "      <td>held</td>\n",
       "      <td>in</td>\n",
       "      <td>...</td>\n",
       "      <td>himself</td>\n",
       "      <td>on</td>\n",
       "      <td>remaining</td>\n",
       "      <td>single</td>\n",
       "      <td>for</td>\n",
       "      <td>his</td>\n",
       "      <td>dear</td>\n",
       "      <td>daughters</td>\n",
       "      <td>sake</td>\n",
       "      <td>For</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>daughter</td>\n",
       "      <td>his</td>\n",
       "      <td>eldest</td>\n",
       "      <td>he</td>\n",
       "      <td>would</td>\n",
       "      <td>really</td>\n",
       "      <td>have</td>\n",
       "      <td>given</td>\n",
       "      <td>up</td>\n",
       "      <td>...</td>\n",
       "      <td>good</td>\n",
       "      <td>looks</td>\n",
       "      <td>of</td>\n",
       "      <td>everybody</td>\n",
       "      <td>else</td>\n",
       "      <td>for</td>\n",
       "      <td>he</td>\n",
       "      <td>could</td>\n",
       "      <td>plainly</td>\n",
       "      <td>see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how</td>\n",
       "      <td>old</td>\n",
       "      <td>all</td>\n",
       "      <td>the</td>\n",
       "      <td>rest</td>\n",
       "      <td>of</td>\n",
       "      <td>his</td>\n",
       "      <td>family</td>\n",
       "      <td>and</td>\n",
       "      <td>acquaintance</td>\n",
       "      <td>...</td>\n",
       "      <td>marry</td>\n",
       "      <td>him</td>\n",
       "      <td>and</td>\n",
       "      <td>her</td>\n",
       "      <td>father</td>\n",
       "      <td>had</td>\n",
       "      <td>always</td>\n",
       "      <td>meant</td>\n",
       "      <td>that</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>should</td>\n",
       "      <td>He</td>\n",
       "      <td>had</td>\n",
       "      <td>not</td>\n",
       "      <td>been</td>\n",
       "      <td>known</td>\n",
       "      <td>to</td>\n",
       "      <td>them</td>\n",
       "      <td>as</td>\n",
       "      <td>a</td>\n",
       "      <td>...</td>\n",
       "      <td>him</td>\n",
       "      <td>to</td>\n",
       "      <td>be</td>\n",
       "      <td>worth</td>\n",
       "      <td>thinking</td>\n",
       "      <td>of</td>\n",
       "      <td>again</td>\n",
       "      <td>The</td>\n",
       "      <td>disgrace</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1     2          3        4      5       6       7    \\\n",
       "0  Persuasion        by  Jane     Austen  Chapter    Sir  Walter  Elliot   \n",
       "1        lord        be  more  delighted     with    the   place      he   \n",
       "2         one  daughter   his     eldest       he  would  really    have   \n",
       "3         how       old   all        the     rest     of     his  family   \n",
       "4      should        He   had        not     been  known      to    them   \n",
       "\n",
       "     8             9    ...      390    391        392        393       394  \\\n",
       "0     of      Kellynch  ...       he    did        nor      could       the   \n",
       "1   held            in  ...  himself     on  remaining     single       for   \n",
       "2  given            up  ...     good  looks         of  everybody      else   \n",
       "3    and  acquaintance  ...    marry    him        and        her    father   \n",
       "4     as             a  ...      him     to         be      worth  thinking   \n",
       "\n",
       "     395     396        397       398   399  \n",
       "0  valet      of        any       new  made  \n",
       "1    his    dear  daughters      sake   For  \n",
       "2    for      he      could   plainly   see  \n",
       "3    had  always      meant      that   she  \n",
       "4     of   again        The  disgrace    of  \n",
       "\n",
       "[5 rows x 400 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(text[1]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = text[0] + text[1] + text[2] + text[3] + text[4] + text[5] + text[6] + text[7] + text[8] + text[9] + text[10] + text[11] + text[12] + text[13] + text[14] + text[15] + text[16] + text[17]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(18):\n",
    "    labels = labels + ([i]*len(text[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5331"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5331"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer(num_words=200000)\n",
    "tok.fit_on_texts(train)\n",
    "train_sequences = tok.texts_to_sequences(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[400])\n",
    "    layer = Embedding(200000,50,input_length=400)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(209,name='FC1',activation = 'relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(209,name='FC2',activation = 'relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer',activation = 'sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 400, 50)           10000000  \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 209)               13585     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 209)               0         \n",
      "_________________________________________________________________\n",
      "FC2 (Dense)                  (None, 209)               43890     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 209)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 210       \n",
      "=================================================================\n",
      "Total params: 10,087,125\n",
      "Trainable params: 10,087,125\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = np.array(train_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 17, 17, 17])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
